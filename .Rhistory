label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train
label_train <- label_train[subset]
dim(da)
dim(dat)
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dat
dim(dat)
n_files <- length(list.files(img_train_dir))
### store image dimensions
dat <- matrix(NA, nrow = n_files, ncol = 3)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows? A lot at 500 rows.  Maybe a good subset to consider.
table(dat[, 1])
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dim(dat)
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[row,] <- rowMeans(img)
row <- row + 1
}
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
length(label_train)
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
train <- function(dat_train, label_train, par = NULL){
### Train a Gradient Boosting Model (GBM) using processed features from training images
### Input:
###  -  processed features from images
###  -  class labels for training images
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
fit_gbm <- gbm.fit(x = dat_train, y = label_train,
n.trees = 2000,
distribution = "bernoulli",
interaction.depth = depth,
bag.fraction = 0.5,
verbose = FALSE)
best_iter <- gbm.perf(fit_gbm, method = "OOB", plot.it = FALSE)
return(list(fit = fit_gbm, iter = best_iter))
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
source("../lib/cross_validation.R")
source("../lib/train.R")
source("../lib/test.R")
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
warnings()
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.25))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
err_cv[,1]
err_cv
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
model_best <- model_values[which.min(err_cv[, 1])]
par_best <- list(depth = model_best)
par_best
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat, label_train, par_best))
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/Kai Li/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-2")
source("./lib/functions.R")
dir_MS <- "/data/Proj3_Data/MS_sample/"
load("./output/MS_UI.Rdata")
load("./output/movie_UI.Rdata")
data_m <- movie_UI[1:20,]
mean <- colMeans(data,na.rm = FALSE, dims = 1)
View(data_m)
# Iniate the similarity weight matrix
data       <- as.matrix(data)
# Iniate the similarity weight matrix
data       <- as.matrix(data)
data_m <- movie_UI[1:20,]
data       <- as.matrix(data)
data  <- movie_UI[1:20,]
# Iniate the similarity weight matrix
data       <- as.matrix(data)
# Iniate the similarity weight matrix
data       <- as.matrix(data)
mean <- colMeans(data, na.rm = FALSE, dims = 1)
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- data-mean
View(data)
View(data)
View(data_sub_mean)
View(data_sub_mean)
View(data_sub_mean)
View(data_sub_mean)
View(data_sub_mean)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean)
vari <- colSums(data_sub_mean,na.rm = FALSE, dims = 1)
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = FALSE, dims = 1)
vari
(data-mean)^2
data_sub_mean[1:10,1:10]
colSums(data_sub_mean, na.rm = FALSE, dims = 1)
vari <- colSums(data_sub_mean, na.rm = T, dims = 1)
vari
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[i,])
min  <- min(data[i,])
var_weight[i] <- (vari[i] -min )/max
}
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
for (i in 1:ncol(data)) {
max  <- max(data[i,])
min  <- min(data[i,])
var_weight[i] <- (vari[i] -min )/max
}
for (i in 1:ncol(data)) {
max  <- max(data[,i])
min  <- min(data[,i])
var_weight[i] <- (vari[i] -min )/max
}
var_weight
max  <- max(data[,i])
i =1
max  <- max(data[,i])
max
max  <- max(data[,i],na.rm=T)
max
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] -min )/max
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] -min )/max
}
vari_weight
var_weight
vari[31]
i =31
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
max
min
(vari[i] - min)/max
var_weight[31]
vari[33]
data[,33]
# Calculate significance weighting
calc_significance <- function(data) {
## Calculate significance coefficient matri
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: significance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
sig_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
significance_func <- function(rowA, rowB) {
# weight_func takes as input two rows (thought of as rows of the data matrix) and
# calculates the similarity between the two rows according to 'method'
joint_values <- !is.na(rowA) & !is.na(rowB)
k <-  length(rowA[joint_values])
if (k >= 50) {
num <- 1
return(num)
}
else {
num <- k/50
return(num)
}
}
# Loops over the rows and calculate sall similarities using significance_func
for(i in 1:nrow(data)) {
sig_weight[i, ] <- apply(data, 1, significance_func, data[i, ])
print(i)
}
return(sig_weight)
}
data  <- movie_UI[1:20,]
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
calc_variance(movie_UI)
var_weight[33]
var_weight[1:100]
movie_UI[1:100,33]
movie_UI[,33]
sum(is.na(movie_UI[,33]))
Subs1 <- na.omit(movie_UI[,33])
Subs1
i = 33
max  <- max(data[,i], na.rm=T)
data <- movie_UI
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
var_weight[i] <- (vari[i] - min)/max
var_weight[33]
data  <- movie_UI[1:20,]
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
data  <- movie_UI[1:20,]
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
data  <- movie_UI[1:20,]
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
var-_weight
var_weight
i = 282
data <- movie_UI
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
calc_variance(data)
var_weight
i = 51
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
max
minm
min
var_weight[i] <- (vari[i] - min)/max
var_weight[i]
ncol(data
)
var_weight <- matrix(NA, 1, ncol = nrow(data))
var_weight <- matrix(NA, 1, ncol = ncol(data))
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, 1, ncol = ncol(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
calc_weight(data)
var_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
var_weight <- matrix(NA, ncol = ncol(data))
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, ncol = ncol(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
var_weight
var_weight[1,1:1000]
View(var_weight)
View(var_weight)
setwd("/Users/Kai Li/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-2")
source("./lib/functions.R")
dir_MS <- "/data/Proj3_Data/MS_sample/"
load("./output/MS_UI.Rdata")
load("./output/movie_UI.Rdata")
# Calculate significance weighting
calc_significance <- function(data) {
## Calculate significance coefficient matri
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: significance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
sig_weight <- matrix(NA, nrow = nrow(data), ncol = nrow(data))
significance_func <- function(rowA, rowB) {
# weight_func takes as input two rows (thought of as rows of the data matrix) and
# calculates the similarity between the two rows according to 'method'
joint_values <- !is.na(rowA) & !is.na(rowB)
k <-  length(rowA[joint_values])
if (k >= 50) {
num <- 1
return(num)
}
else {
num <- k/50
return(num)
}
}
# Loops over the rows and calculate sall similarities using significance_func
for(i in 1:nrow(data)) {
sig_weight[i, ] <- apply(data, 1, significance_func, data[i, ])
print(i)
}
return(sig_weight)
}
calc_variance <- function(data) {
## Calculate variance weighting matrix
##
## input: data   - movie data or MS data in user-item matrix form
##
## output: variance weighting matrix
# Iniate the similarity weight matrix
data       <- as.matrix(data)
var_weight <- matrix(NA, ncol = ncol(data))
mean <- colMeans(data, na.rm = T, dims = 1)
data_sub_mean <- (data-mean)^2
vari <- colSums(data_sub_mean, na.rm = T, dims = 1) / (ncol(data_sub_mean)-1)
for (i in 1:ncol(data)) {
max  <- max(data[,i], na.rm=T)
min  <- min(data[,i], na.rm=T)
var_weight[i] <- (vari[i] - min)/max
}
return(var_weight)
}
calc_significance(data)
calc_variance(data)
calc_significance(movie_UI)
calc_variance(movie_UI)
source("./lib/functions.R")
setwd("/Users/Kai Li/Documents/GitHub/project-3-algorithms-project-3-algorithms-group-2")
source("./lib/functions.R")
# install.packages("DescTools")
library("DescTools")
# install.packages("infotheo")
library("infotheo")
tm_MS_spm <- system.time(MS_spm <-
calc_weight(MS_UI, run.spearman = T))
save(MS_spm, file = "./output/MS_spm.RData")
tm_movie_cos
tm_MS_spm
save(MS_spm, file = "./output/MS_spm.RData")
tm_movie_cos <- system.time(movie_cos <-
calc_weight(movie_UI,run.cosin = T))
tm_movie_sqd <- system.time(movie_sqd <-
calc_weight(movie_UI,run.sqdiff = T))
tm_movie_cos <- system.time(movie_cos <-
calc_weight(movie_UI,run.cosin = T))
tm_movie_cos
tm_MS_spm
